{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to analyze parquet file using spark sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hconf = sc._jsc.hadoopConfiguration()  \n",
    "hconf.set(\"fs.s3a.access.key\", \"AKIAYHI6A5QQ3AQYGP4Z\")\n",
    "hconf.set(\"fs.s3a.secret.key\", \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.version\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.parquet(\"s3a://akdatalake/sor/customeractivity.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"customeractivity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------+----------------+------------------------+-------------------------+------------------------+------------------+------------------+--------------------+---------------------+\n",
      "| ID|TotalDollarValueTraded|TotalUnitsTraded|LargestSingleTransaction|SmallestSingleTransaction|PercentChangeCalculation|DaysSinceLastLogin|DaysSinceLastTrade|NetRealizedGains_YTD|NetRealizedLosses_YTD|\n",
      "+---+----------------------+----------------+------------------------+-------------------------+------------------------+------------------+------------------+--------------------+---------------------+\n",
      "|  0|              59755.98|             206|                29877.99|       2987.7990000000004|                    51.5|                 3|                10|  2987.7990000000004|                  0.0|\n",
      "|  1|              29782.98|              45|                14891.49|                 1489.149|                   11.25|                 3|                 9|            1489.149|                  0.0|\n",
      "|  2|              24812.48|              22|                12406.24|                 1240.624|                     5.5|                 1|                 9|            1240.624|                  0.0|\n",
      "|  3|              26132.61|              32|               13066.305|                1306.6305|                     8.0|                 3|                 5|                 0.0|            1306.6305|\n",
      "|  4|                5030.5|              23|                1257.625|                 125.7625|                    3.45|                 2|                19|                 0.0|              251.525|\n",
      "+---+----------------------+----------------+------------------------+-------------------------+------------------------+------------------+------------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from customeractivity \").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=spark.read.parquet(\"s3a://akdatalake/sor/customerdemographic.parquet\")\n",
    "df2.createOrReplaceTempView(\"customerdemography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+---------+---------+---+\n",
      "| ID|Gender|Status|Children|EstIncome|HomeOwner|Age|\n",
      "+---+------+------+--------+---------+---------+---+\n",
      "|  0|     F|     S|       1|  38000.0|        N| 24|\n",
      "|  1|     M|     M|       2|  29616.0|        N| 49|\n",
      "|  2|     M|     M|       0|  19732.8|        N| 51|\n",
      "|  3|     M|     S|       2|    96.33|        N| 56|\n",
      "|  4|     F|     M|       2|  52004.8|        N| 25|\n",
      "+---+------+------+--------+---------+---------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from customerdemography\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+---+---------+----------------------+----------------+\n",
      "| ID|Gender|Status|Children|Age|EstIncome|TotalDollarValueTraded|TotalUnitsTraded|\n",
      "+---+------+------+--------+---+---------+----------------------+----------------+\n",
      "|  0|     F|     S|       1| 24|  38000.0|              59755.98|             206|\n",
      "|  1|     M|     M|       2| 49|  29616.0|              29782.98|              45|\n",
      "|  2|     M|     M|       0| 51|  19732.8|              24812.48|              22|\n",
      "|  3|     M|     S|       2| 56|    96.33|              26132.61|              32|\n",
      "|  4|     F|     M|       2| 25|  52004.8|                5030.5|              23|\n",
      "+---+------+------+--------+---+---------+----------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=spark.sql(\"select a.ID,Gender,Status,Children, Age,EstIncome ,TotalDollarValueTraded ,TotalUnitsTraded from customeractivity a ,customerdemography b where a.ID=b.ID\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=spark.sql(\"select a.ID,Gender,Status,Children, Age,EstIncome ,TotalDollarValueTraded ,TotalUnitsTraded from customeractivity a ,customerdemography b where a.ID=b.ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also save the file as well\n",
    "# note: make sure the file does not exist first\n",
    "df3.write.parquet(\"s3a://akdatalake/queryzone/customer-hunglb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file again\n",
    "spark.read.parquet(\"s3a://akdatalake/queryzone/customer-hunglb.parquet\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
